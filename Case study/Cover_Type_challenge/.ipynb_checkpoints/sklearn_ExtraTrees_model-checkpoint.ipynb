{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@author: Valentin Larrieu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectFpr, f_regression, f_classif\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3 : ExtraTrees with Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape before drop (528720, 71)\n",
      "shape after drop (528720, 63)\n"
     ]
    }
   ],
   "source": [
    "# We need pandas dataframe for sklearn\n",
    "df_train = pd.read_csv('Files\\\\train-set.csv')\n",
    "df_test = pd.read_csv('Files\\\\test-set.csv')\n",
    "\n",
    "\n",
    "Y = df_train.Cover_Type\n",
    "\n",
    "# We drop the ID column because it do not give usefull information\n",
    "X = df_train.drop(['Id','Cover_Type'],axis=1)\n",
    "X_test_input = df_test.drop('Id',axis=1)\n",
    "\n",
    "#Feature creation\n",
    "X[\"distance\"] = np.sqrt(X.Horizontal_Distance_To_Hydrology**2 + X.Vertical_Distance_To_Hydrology**2)\n",
    "X[\"High\"] = X.Elevation+ X.Vertical_Distance_To_Hydrology \n",
    "X[\"Shade_mean\"] = (X.Hillshade_9am+X.Hillshade_Noon+X.Hillshade_3pm)/3\n",
    "X[\"slope_shade\"] = X.Slope/ X.Shade_mean\n",
    "X[\"elevation_shade\"] = X.Elevation/ X.Shade_mean\n",
    "X[\"slope_elevation\"] = X.Slope/ X.Elevation\n",
    "X['Hydro_slope'] = X.Vertical_Distance_To_Hydrology / X.Horizontal_Distance_To_Hydrology\n",
    "\n",
    "# We try to create features that can be separated verticaly\n",
    "X['Hydro_elev']=X.Elevation - 0.2 * X.Horizontal_Distance_To_Hydrology\n",
    "X['Road_elev']=X.Elevation - 0.05 * X.Horizontal_Distance_To_Roadways\n",
    "X['Hydro_elev_vert']=X.Elevation - X.Vertical_Distance_To_Hydrology\n",
    "X['Horiz_mean']=(X.Horizontal_Distance_To_Fire_Points + X.Horizontal_Distance_To_Hydrology + X.Horizontal_Distance_To_Roadways) / 3\n",
    "X['Horiz_fire_hydr']=(X.Horizontal_Distance_To_Fire_Points + X.Horizontal_Distance_To_Hydrology) / 2\n",
    "X['Horiz_hydr_road']=(X.Horizontal_Distance_To_Roadways + X.Horizontal_Distance_To_Hydrology) / 2\n",
    "X['Horiz_road_fire']=(X.Horizontal_Distance_To_Roadways + X.Horizontal_Distance_To_Hydrology) / 2\n",
    "X['Horiz_diff_fire_hydr']=abs(X.Horizontal_Distance_To_Fire_Points - X.Horizontal_Distance_To_Hydrology)\n",
    "X['Horiz_diff_hydr_road']=abs(X.Horizontal_Distance_To_Roadways - X.Horizontal_Distance_To_Hydrology)\n",
    "X['Horiz_diff_road_fire']=abs(X.Horizontal_Distance_To_Roadways - X.Horizontal_Distance_To_Hydrology)\n",
    "\n",
    "\n",
    "X_test_input[\"distance\"] = np.sqrt(X_test_input.Horizontal_Distance_To_Hydrology**2 + X_test_input.Vertical_Distance_To_Hydrology**2)\n",
    "X_test_input[\"High\"] = X_test_input.Elevation+ X_test_input.Vertical_Distance_To_Hydrology \n",
    "X_test_input[\"Shade_mean\"] = (X_test_input.Hillshade_9am+X_test_input.Hillshade_Noon+X_test_input.Hillshade_3pm)/3\n",
    "X_test_input[\"slope_shade\"] = X_test_input.Slope/ X_test_input.Shade_mean\n",
    "X_test_input[\"elevation_shade\"] = X_test_input.Elevation/ X_test_input.Shade_mean\n",
    "X_test_input[\"slope_elevation\"] = X_test_input.Slope/ X_test_input.Elevation \n",
    "X_test_input['Hydro_slope'] = X_test_input.Vertical_Distance_To_Hydrology / X_test_input.Horizontal_Distance_To_Hydrology\n",
    "X_test_input['Hydro_elev']=X_test_input.Elevation - 0.2 * X_test_input.Horizontal_Distance_To_Hydrology\n",
    "X_test_input['Road_elev']=X_test_input.Elevation - 0.05 * X_test_input.Horizontal_Distance_To_Roadways\n",
    "X_test_input['Hydro_elev_vert']=X_test_input.Elevation - X_test_input.Vertical_Distance_To_Hydrology\n",
    "X_test_input['Horiz_mean']=(X_test_input.Horizontal_Distance_To_Fire_Points + X_test_input.Horizontal_Distance_To_Hydrology + X_test_input.Horizontal_Distance_To_Roadways) / 3\n",
    "X_test_input['Horiz_fire_hydr']=(X_test_input.Horizontal_Distance_To_Fire_Points + X_test_input.Horizontal_Distance_To_Hydrology) / 2\n",
    "X_test_input['Horiz_hydr_road']=(X_test_input.Horizontal_Distance_To_Roadways + X_test_input.Horizontal_Distance_To_Hydrology) / 2\n",
    "X_test_input['Horiz_hydr_road']=(X_test_input.Horizontal_Distance_To_Roadways + X_test_input.Horizontal_Distance_To_Hydrology) / 2\n",
    "X_test_input['Horiz_road_fire']=(X_test_input.Horizontal_Distance_To_Roadways + X_test_input.Horizontal_Distance_To_Hydrology) / 2\n",
    "X_test_input['Horiz_diff_fire_hydr']=abs(X_test_input.Horizontal_Distance_To_Fire_Points - X_test_input.Horizontal_Distance_To_Hydrology)\n",
    "X_test_input['Horiz_diff_hydr_road']=abs(X_test_input.Horizontal_Distance_To_Roadways - X_test_input.Horizontal_Distance_To_Hydrology)\n",
    "X_test_input['Horiz_diff_road_fire']=abs(X_test_input.Horizontal_Distance_To_Roadways - X_test_input.Horizontal_Distance_To_Hydrology)\n",
    "\n",
    "# We remove the infinite values the column division could have created\n",
    "X.Shade_mean=X.Shade_mean.map(lambda x: 0 if np.isinf(x) else x)\n",
    "X.slope_shade=X.slope_shade.map(lambda x: 0 if np.isinf(x) else x)\n",
    "X.elevation_shade=X.elevation_shade.map(lambda x: 0 if np.isinf(x) else x)\n",
    "X.Hydro_slope=X.Hydro_slope.map(lambda x: 0 if np.isinf(x) else x)\n",
    "X.slope_elevation=X.slope_elevation.map(lambda x: 0 if np.isinf(x) else x)\n",
    "\n",
    "X_test_input.Shade_mean=X_test_input.Shade_mean.map(lambda x: 0 if np.isinf(x) else x)\n",
    "X_test_input.slope_shade=X_test_input.slope_shade.map(lambda x: 0 if np.isinf(x) else x)\n",
    "X_test_input.elevation_shade=X_test_input.elevation_shade.map(lambda x: 0 if np.isinf(x) else x)\n",
    "X_test_input.Hydro_slope=X_test_input.Hydro_slope.map(lambda x: 0 if np.isinf(x) else x)\n",
    "X_test_input.slope_elevation=X_test_input.slope_elevation.map(lambda x: 0 if np.isinf(x) else x)\n",
    "\n",
    "X[X==np.inf] = np.nan\n",
    "X.fillna(X.mean(), inplace=True)\n",
    "X_test_input[X_test_input==np.inf] = np.nan\n",
    "X_test_input.fillna(X_test_input.mean(), inplace=True)\n",
    "\n",
    "#Feature selection\n",
    "print(\"shape before drop\", X.shape)\n",
    "\n",
    "# Normalisation of the data\n",
    "sc = StandardScaler()\n",
    "model_centered = sc.fit(X)\n",
    "X = model_centered.transform(X)\n",
    "model_centered = sc.fit(X_test_input)\n",
    "X_test_input = model_centered.transform(X_test_input)\n",
    "\n",
    "# Feature selection\n",
    "sel = SelectFpr(f_regression,alpha=0.000001)\n",
    "model_sel = sel.fit(X,Y)\n",
    "X = sel.transform(X)\n",
    "X_test_input = sel.transform(X_test_input)\n",
    "\n",
    "print(\"shape after drop\", X.shape)\n",
    "\n",
    "# We split our data\n",
    "X_train,X_test,Y_train,Y_test = model_selection.train_test_split(X,Y,test_size=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.96      0.95      0.96     19288\n",
      "          2       0.96      0.97      0.96     25933\n",
      "          3       0.95      0.96      0.96      3197\n",
      "          4       0.90      0.86      0.88       278\n",
      "          5       0.92      0.85      0.88       809\n",
      "          6       0.93      0.89      0.91      1506\n",
      "          7       0.97      0.96      0.97      1861\n",
      "\n",
      "avg / total       0.96      0.96      0.96     52872\n",
      "\n",
      "ExtraTrees Accuracy : 0.957614616432138\n"
     ]
    }
   ],
   "source": [
    "# We fit our model\n",
    "et = AdaBoostClassifier(ExtraTreesClassifier(n_estimators=300, criterion= 'entropy', n_jobs = -1, warm_start=True, max_features = 20), n_estimators=1000, learning_rate=0.0001, algorithm='SAMME.R')\n",
    "\n",
    "et.fit(X_train,Y_train)\n",
    "\n",
    "# We use it to predict our output\n",
    "Y_hat = et.predict(X_test)\n",
    "\n",
    "# We print the results\n",
    "print(metrics.classification_report(Y_test,Y_hat))\n",
    "print(\"ExtraTrees Accuracy :\", metrics.accuracy_score(Y_test,Y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We retrain our model with our entire set to have the best model for kaggle\n",
    "et2 = AdaBoostClassifier(ExtraTreesClassifier(n_estimators=300, criterion= 'entropy', n_jobs = -1, warm_start=True, max_features = 19), n_estimators=300, learning_rate=0.01, algorithm='SAMME.R')\n",
    "\n",
    "et2.fit(X,Y)\n",
    "Y_hat_export2 = et2.predict(X_test_input)\n",
    "\n",
    "export_df2 = pd.DataFrame({'Id':df_test.Id.values,'Cover_Type':Y_hat_export2}).sort_index(ascending=False,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export_df2.to_csv('submit\\\\submission_local.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
