{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[887   2]\n",
      " [ 16  95]]\n",
      "[[878  11]\n",
      " [ 15  96]]\n",
      "[[728 161]\n",
      " [ 12  99]]\n",
      "\n",
      " Model 1 : Linear SVC : \n",
      "r2 score : = 0.817590368771\n",
      "Confusion Matrix : [[887   2]\n",
      " [ 16  95]]\n",
      "Verification : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99       889\n",
      "          1       0.98      0.86      0.91       111\n",
      "\n",
      "avg / total       0.98      0.98      0.98      1000\n",
      "\n",
      "\n",
      " Model 2 : MultinomialNB : \n",
      "r2 score : = 0.736519421559\n",
      "Confusion Matrix : [[878  11]\n",
      " [ 15  96]]\n",
      "Verification : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.99      0.99       889\n",
      "          1       0.90      0.86      0.88       111\n",
      "\n",
      "avg / total       0.97      0.97      0.97      1000\n",
      "\n",
      "\n",
      " Model 3 : GaussianNB : \n",
      "r2 score : = -0.753159233474\n",
      "Confusion Matrix : [[728 161]\n",
      " [ 12  99]]\n",
      "Verification : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.82      0.89       889\n",
      "          1       0.38      0.89      0.53       111\n",
      "\n",
      "avg / total       0.92      0.83      0.85      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "df=pd.read_csv(\"./Files/messages.txt\", sep='\\t')\n",
    "X=df[[1]]\n",
    "y=df[[0]].replace({'ham': 0, 'spam': 1}) #Spam will be 1 and ham 0\n",
    "\n",
    "#we randomly change the order of line in order to limit possible bias (such as sorted dataset for instance)\n",
    "n_sample = len(X)\n",
    "np.random.seed(0) #We set the seed to be 0 to have the same results on each computer\n",
    "order = np.random.permutation(n_sample)\n",
    "X=X.as_matrix() #We convert to matrix and order to change the order of the lines\n",
    "y=y.as_matrix()\n",
    "X = X[order]\n",
    "y = y[order]\n",
    "\n",
    "#We choose for our model to be 80/20 partitionized : 80% training and 20% test\n",
    "X_train = X[:int(.8 * n_sample)]\n",
    "X_train=pd.DataFrame(X_train).stack()#We reconvert to a dataframe for the rest of the program\n",
    "y_train = y[:int(.8 * n_sample)]\n",
    "y_train=pd.DataFrame(y_train).stack()\n",
    "X_test = X[int(.8 * n_sample):]\n",
    "X_test=pd.DataFrame(X_test).stack()\n",
    "y_test = y[int(.8 * n_sample):]\n",
    "y_test=pd.DataFrame(y_test).stack()\n",
    "\n",
    "\n",
    "def make_Dictionary(X):\n",
    "    all_words = []\n",
    "    for line in X:\n",
    "        words = line.split()\n",
    "        all_words += words\n",
    "\n",
    "    dictionary = Counter(all_words)\n",
    "    # list_to_remove = dictionary.keys()\n",
    "    # for item in list_to_remove: # this works with python 2.x version\n",
    "    for item in list(dictionary): # this works with python 3.x version\n",
    "        if item.isalpha() == False:\n",
    "            del dictionary[item]\n",
    "        elif len(item) == 1:\n",
    "            del dictionary[item]\n",
    "    dictionary = dictionary.most_common(3000)\n",
    "    return dictionary\n",
    "\n",
    "def extract_features(X):\n",
    "\n",
    "    features_matrix = np.zeros((len(X), 3000))\n",
    "    docID = 0\n",
    "    for line in X:\n",
    "        words = line.split()\n",
    "        for word in words:\n",
    "            wordID = 0\n",
    "            for i, d in enumerate(dictionary):\n",
    "                if d[0] == word:\n",
    "                    wordID = i\n",
    "                    features_matrix[docID, wordID] = words.count(word)\n",
    "        docID = docID + 1\n",
    "    return features_matrix\n",
    "\n",
    "# Create a dictionary of words with its frequency\n",
    "dictionary = make_Dictionary(X_train)\n",
    "\n",
    "\n",
    "# Prepare feature vectors per training mail and its labels\n",
    "train_matrix = extract_features(X_train)\n",
    "\n",
    "\n",
    "# Training SVM and Naive bayes classifier and its variants\n",
    "model1 = LinearSVC()\n",
    "model2 = MultinomialNB()\n",
    "model3 = GaussianNB()\n",
    "model1.fit(train_matrix, y_train)\n",
    "model2.fit(train_matrix, y_train)\n",
    "model3.fit(train_matrix, y_train)\n",
    "\n",
    "# Test the unseen mails for Spam\n",
    "test_matrix = extract_features(X_test)\n",
    "result1 = model1.predict(test_matrix)\n",
    "result2 = model2.predict(test_matrix)\n",
    "result3= model3.predict(test_matrix)\n",
    "\n",
    "#We verify our results\n",
    "print(confusion_matrix(y_test, result1))\n",
    "print(confusion_matrix(y_test, result2))\n",
    "print(confusion_matrix(y_test, result3))\n",
    "\n",
    "#Evaluation  of model 1 :\n",
    "print(\"\\n Model 1 : Linear SVC : \")\n",
    "print(\"r2 score : =\", r2_score(y_test, result1))\n",
    "#We print the confusion matrix\n",
    "print (\"Confusion Matrix :\", metrics.confusion_matrix(y_test, result1))\n",
    "# We print the classification matrix\n",
    "print('Verification : \\n', metrics.classification_report(y_test, result1))\n",
    "\n",
    "#Evaluation  of model 2 :\n",
    "print(\"\\n Model 2 : MultinomialNB : \")\n",
    "print(\"r2 score : =\", r2_score(y_test, result2))\n",
    "#We print the confusion matrix\n",
    "print (\"Confusion Matrix :\", metrics.confusion_matrix(y_test, result2))\n",
    "# We print the classification matrix\n",
    "print('Verification : \\n', metrics.classification_report(y_test, result2))\n",
    "\n",
    "#Evaluation  of model 3 :\n",
    "print(\"\\n Model 3 : GaussianNB : \")\n",
    "print(\"r2 score : =\", r2_score(y_test, result3))\n",
    "#We print the confusion matrix\n",
    "print (\"Confusion Matrix :\", metrics.confusion_matrix(y_test, result3))\n",
    "# We print the classification matrix\n",
    "print('Verification : \\n', metrics.classification_report(y_test, result3))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
