{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use of convolutions with tensorflow\n",
    "\n",
    "In this notebook, we will use tensorflow to build a Convolutional Neural Network (CNN).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution\n",
    "\n",
    "Ressources :  [this notebook](https://nbviewer.jupyter.org/github/marc-moreaux/Deep-Learning-classes/blob/master/notebooks/Convolution.ipynb) and this [wikipedia page](https://en.wikipedia.org/wiki/Convolution)\n",
    "\n",
    "no, if we consider two functions $f$ and $g$ taking values from $\\mathbb{Z} \\to \\mathbb{R}$ then:  \n",
    "$ (f * g)[n] = \\sum_{m = -\\infty}^{+\\infty} f[m] \\cdot g[n - m] $\n",
    "\n",
    "In our case, we consider the two vectors $x$ and $w$ :  \n",
    "$ x = (x_1, x_2, ..., x_{n-1}, x_n) $  \n",
    "$ w = (w_1, w_2) $\n",
    "\n",
    "And get :   \n",
    "$ x * w = (w_1 x_1 + w_2 x_2, w_1 x_2 + w_2 x_3, ..., w_1 x_{n-1} + w_2 x_n)$\n",
    "\n",
    "\n",
    "#### Deep learning subtility :\n",
    "    \n",
    "In most of deep learning framewoks, we need to chose in between three paddings:\n",
    "- **Same**: $(f*g)$ has the same shape as x (we pad the entry with zeros)\n",
    "- **valid**: $(f*g)$ has the shape of x minus the shape of w plus 1 (no padding on x)\n",
    "- **Causal**: $(f*g)(n_t)$ does not depend on any $(n_{t+1})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow\n",
    "\n",
    "\"TensorFlow is an open-source software library for dataflow programming across a range of tasks. It is a symbolic math library, and also used for machine learning applications such as neural networks.[3] It is used for both research and production at Google often replacing its closed-source predecessor, DistBelief.\" - Wikipedia\n",
    "\n",
    "We'll be using tensorflow to build the models we want to use. \n",
    "\n",
    "Here below, we build a AND gate with a very simple neural network :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00839782]\n",
      " [ 0.1499088 ]\n",
      " [ 0.1499088 ]\n",
      " [ 0.78595555]] Tensor(\"Y:0\", shape=(?, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Define our Dataset\n",
    "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "Y = np.array([0,0,0,1]).reshape(-1,1)\n",
    "\n",
    "\n",
    "# Define the tensorflow tensors\n",
    "x = tf.placeholder(tf.float32, [None, 2], name='X')  # inputs\n",
    "y = tf.placeholder(tf.float32, [None, 1], name='Y')  # outputs\n",
    "W = tf.Variable(tf.zeros([2, 1]), name='W')\n",
    "b = tf.Variable(tf.zeros([1,]), name='b')\n",
    "\n",
    "# Define the model\n",
    "pred = tf.nn.sigmoid(tf.matmul(x, W) + b)  # Model\n",
    "\n",
    "# Define the loss\n",
    "with tf.name_scope(\"loss\"):\n",
    "    loss = tf.reduce_mean(-tf.reduce_sum(y * tf.log(pred) + (1-y) * tf.log(1-pred), reduction_indices=1))\n",
    "\n",
    "# Define the optimizer method you want to use\n",
    "with tf.name_scope(\"optimizer\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.1).minimize(loss)\n",
    "\n",
    "# Include some Tensorboard visualization\n",
    "writer_train = tf.summary.FileWriter(\"./my_model/\")\n",
    "\n",
    "\n",
    "# Start training session\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    writer_train.add_graph(sess.graph)\n",
    "    \n",
    "    for epoch in range(1000):\n",
    "        _, c, p = sess.run([optimizer, loss, pred], feed_dict={x: X,\n",
    "                                                      y: Y})\n",
    "print (p, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize the graph you just created, launch tensorbord.  \n",
    "`$tensorboard --logdirs=./` on linux (with corresponding logdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Building a XOR gate\n",
    "\n",
    "Design a neural network with 2 layers.\n",
    "- layer1 has 2 neurons (sigmoid or tanh activation)\n",
    "- Layer2 has 1 neuron (it outouts the prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.01878518]\n",
      " [ 0.49531072]\n",
      " [ 0.97386271]\n",
      " [ 0.51125109]] Tensor(\"Y:0\", shape=(?, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Define our Dataset\n",
    "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "Y = np.array([0,1,1,0]).reshape(-1,1)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Define the tensorflow tensors\n",
    "x = tf.placeholder(tf.float32, [None, 2], name='X')  # inputs\n",
    "y = tf.placeholder(tf.float32, [None, 1], name='Y')  # outputs\n",
    "W1 = tf.Variable(tf.random_normal([2, 2]), name='W1') #Weights matrixes\n",
    "W2 = tf.Variable(tf.random_normal([2, 1]), name='W2')\n",
    "#b1 = tf.Variable(tf.random_normal([2,2],mean=0,stddev=1), name='b1')\n",
    "b1 = tf.Variable(tf.zeros([1,]), name='b1') #Biases\n",
    "b2 = tf.Variable(tf.zeros([1,]), name='b2')\n",
    "#,stddev=0.01\n",
    "\n",
    "# Define the prediction -> that's the data we want to improve\n",
    "#pred = tf.nn.sigmoid(tf.matmul(x, W1) + b1)  # Model\n",
    "pred = tf.nn.sigmoid(tf.matmul(tf.nn.tanh(tf.matmul(x, W1) + b1),W2)+b2)\n",
    "#pred = tf.nn.sigmoid((tf.nn.tanh(tf.matmul(x, W1) + b1)+tf.nn.tanh(tf.matmul(x, W1) + b1)))\n",
    "\n",
    "# Define the loss -> minimizing the loss will result in better predictions -> better model\n",
    "with tf.name_scope(\"loss\"):\n",
    "    loss = tf.reduce_mean(-tf.reduce_sum(y * tf.log(pred) + (1-y) * tf.log(1-pred), reduction_indices=1))\n",
    "    loss_summary = tf.summary.scalar(\"loss\",loss)\n",
    "    \n",
    "# Define the optimizer method we want to use\n",
    "with tf.name_scope(\"optimizer\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.01).minimize(loss) #0.1 is the learning rate\n",
    "\n",
    "# Include some Tensorboard visualization\n",
    "writer_train = tf.summary.FileWriter(\"./my_model/\")\n",
    "\n",
    "\n",
    "# Start training session\n",
    "with tf.Session() as sess:\n",
    "    #Running the session\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    writer_train.add_graph(sess.graph)\n",
    "    \n",
    "    for epoch in range(10000):\n",
    "        _, c, p = sess.run([optimizer, loss, pred], feed_dict={x: X,\n",
    "                                              y: Y})\n",
    "        #We need those to print the weights later on\n",
    "        variables_names = [v.name for v in tf.trainable_variables()]\n",
    "        values = sess.run(variables_names)\n",
    "            \n",
    "\n",
    "        #writer_train.add_summary(ls,epoch)\n",
    "print (p, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see we usually have these results within a 10^-2 margin \n",
    "[[ 0.04336669] -> 0 XOR 0 : 0 \n",
    "[ 0.92657214]  -> 0 XOR 1 : 1\n",
    "[ 0.92823118]  -> 1 XOR 0 : 1\n",
    "[ 0.03871076]] -> 1 XOR 1 : 0\n",
    "So the model is pretty good.\n",
    "Tensor(\"Y:0\", shape=(?, 1), dtype=float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the weights of the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable:  W1:0\n",
      "Shape:  (2, 2)\n",
      "[[-1.30482197 -2.29883933]\n",
      " [ 3.06002903 -3.35569358]]\n",
      "Variable:  W2:0\n",
      "Shape:  (2, 1)\n",
      "[[-2.5333662 ]\n",
      " [-3.04376483]]\n",
      "Variable:  b1:0\n",
      "Shape:  (1,)\n",
      "[ 0.72431636]\n",
      "Variable:  b2:0\n",
      "Shape:  (1,)\n",
      "[-0.50039285]\n"
     ]
    }
   ],
   "source": [
    "for k, v in zip(variables_names, values):\n",
    "    print (\"Variable: \", k)\n",
    "    print (\"Shape: \", v.shape)\n",
    "    print (v)\n",
    "        \n",
    "         \n",
    "#W1:\n",
    "#[[ 2.74875498 -2.75169706]\n",
    "# [-2.72136331  2.83918357]]\n",
    "\n",
    "#W2:\n",
    "#[[-3.58781314]\n",
    "# [-3.57973051]]\n",
    "\n",
    "#The first weights are two opposed vectors basically. So it is meant to balance something at first sight.\n",
    "#When you look at the columns, you look at the weights applied to the entrance of the OR gate. \n",
    "#The OR gate will only give 0 if both entries are at 0, so if any entry is at 1, the result is 1.\n",
    "#In other words, 25% of outputs will be 0, 75% will be 1\n",
    "#Hence a positive weight on the first item (0) and a negative one for the second (1)\n",
    "\n",
    "#Same logic applies to the second column, the NAND will give 1 if there is any 0\n",
    "#So the 0 is weighted negatively and the 1 positively.\n",
    "\n",
    "#For W2, we have a XOR gate. 50% of having either 0 or 1\n",
    "#Hence equal weights for W2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Building a CNN to predict the MNIST digits\n",
    "We will use a Convolutional neural network to predict the digits from MNIST.\n",
    "\n",
    "Ressources : [SNN](https://nbviewer.jupyter.org/github/marc-moreaux/Deep-Learning-classes/blob/master/notebooks/Intro_to_SNN.ipynb)\n",
    "\n",
    "Model :\n",
    "- 1st layer : 6 convolutional kernels with shape (3,3)\n",
    "- 2nd layer : 6 convolutional kernels with shape (3,3)\n",
    "- 3rd layer : Softmax layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "step 0, training accuracy 0.16\n",
      "step 100, training accuracy 0.1\n",
      "step 200, training accuracy 0.28\n",
      "step 300, training accuracy 0.46\n",
      "step 400, training accuracy 0.76\n",
      "step 500, training accuracy 0.66\n",
      "step 600, training accuracy 0.72\n",
      "step 700, training accuracy 0.78\n",
      "step 800, training accuracy 0.78\n",
      "step 900, training accuracy 0.88\n",
      "step 1000, training accuracy 0.9\n",
      "step 1100, training accuracy 0.76\n",
      "step 1200, training accuracy 0.88\n",
      "step 1300, training accuracy 0.78\n",
      "step 1400, training accuracy 0.76\n",
      "step 1500, training accuracy 0.8\n",
      "step 1600, training accuracy 0.8\n",
      "step 1700, training accuracy 0.72\n",
      "step 1800, training accuracy 0.94\n",
      "step 1900, training accuracy 0.86\n",
      "step 2000, training accuracy 0.92\n",
      "step 2100, training accuracy 0.86\n",
      "step 2200, training accuracy 0.82\n",
      "step 2300, training accuracy 0.88\n",
      "step 2400, training accuracy 0.86\n",
      "step 2500, training accuracy 0.76\n",
      "step 2600, training accuracy 0.92\n",
      "step 2700, training accuracy 0.9\n",
      "step 2800, training accuracy 0.88\n",
      "step 2900, training accuracy 0.82\n",
      "step 3000, training accuracy 0.82\n",
      "step 3100, training accuracy 0.86\n",
      "step 3200, training accuracy 0.84\n",
      "step 3300, training accuracy 0.88\n",
      "step 3400, training accuracy 0.84\n",
      "step 3500, training accuracy 0.92\n",
      "step 3600, training accuracy 0.74\n",
      "step 3700, training accuracy 0.86\n",
      "step 3800, training accuracy 0.8\n",
      "step 3900, training accuracy 0.88\n",
      "step 4000, training accuracy 0.9\n",
      "step 4100, training accuracy 0.84\n",
      "step 4200, training accuracy 0.82\n",
      "step 4300, training accuracy 0.88\n",
      "step 4400, training accuracy 0.8\n",
      "step 4500, training accuracy 0.9\n",
      "step 4600, training accuracy 0.86\n",
      "step 4700, training accuracy 0.74\n",
      "step 4800, training accuracy 0.84\n",
      "step 4900, training accuracy 0.84\n",
      "step 5000, training accuracy 0.8\n",
      "step 5100, training accuracy 0.88\n",
      "step 5200, training accuracy 0.84\n",
      "step 5300, training accuracy 0.88\n",
      "step 5400, training accuracy 0.84\n",
      "step 5500, training accuracy 0.88\n",
      "step 5600, training accuracy 0.78\n",
      "step 5700, training accuracy 0.86\n",
      "step 5800, training accuracy 0.86\n",
      "step 5900, training accuracy 0.94\n",
      "step 6000, training accuracy 0.86\n",
      "step 6100, training accuracy 0.86\n",
      "step 6200, training accuracy 0.86\n",
      "step 6300, training accuracy 0.84\n",
      "step 6400, training accuracy 0.88\n",
      "step 6500, training accuracy 0.9\n",
      "step 6600, training accuracy 0.84\n",
      "step 6700, training accuracy 0.9\n",
      "step 6800, training accuracy 0.96\n",
      "step 6900, training accuracy 0.92\n",
      "step 7000, training accuracy 0.86\n",
      "step 7100, training accuracy 0.92\n",
      "step 7200, training accuracy 0.9\n",
      "step 7300, training accuracy 0.92\n",
      "step 7400, training accuracy 0.92\n",
      "step 7500, training accuracy 0.92\n",
      "step 7600, training accuracy 0.9\n",
      "step 7700, training accuracy 0.96\n",
      "step 7800, training accuracy 0.92\n",
      "step 7900, training accuracy 0.88\n",
      "step 8000, training accuracy 0.96\n",
      "step 8100, training accuracy 0.94\n",
      "step 8200, training accuracy 0.92\n",
      "step 8300, training accuracy 0.98\n",
      "step 8400, training accuracy 0.9\n",
      "step 8500, training accuracy 0.9\n",
      "step 8600, training accuracy 0.94\n",
      "step 8700, training accuracy 0.94\n",
      "step 8800, training accuracy 0.9\n",
      "step 8900, training accuracy 0.92\n",
      "step 9000, training accuracy 0.94\n",
      "step 9100, training accuracy 0.92\n",
      "step 9200, training accuracy 0.98\n",
      "step 9300, training accuracy 0.9\n",
      "step 9400, training accuracy 0.94\n",
      "step 9500, training accuracy 0.94\n",
      "step 9600, training accuracy 0.92\n",
      "step 9700, training accuracy 0.94\n",
      "step 9800, training accuracy 0.96\n",
      "step 9900, training accuracy 0.92\n",
      "step 10000, training accuracy 0.92\n",
      "step 10100, training accuracy 0.9\n",
      "step 10200, training accuracy 0.98\n",
      "step 10300, training accuracy 0.98\n",
      "step 10400, training accuracy 0.94\n",
      "step 10500, training accuracy 0.92\n",
      "step 10600, training accuracy 0.96\n",
      "step 10700, training accuracy 0.86\n",
      "step 10800, training accuracy 0.94\n",
      "step 10900, training accuracy 0.86\n",
      "step 11000, training accuracy 0.94\n",
      "step 11100, training accuracy 0.88\n",
      "step 11200, training accuracy 0.86\n",
      "step 11300, training accuracy 0.92\n",
      "step 11400, training accuracy 0.96\n",
      "step 11500, training accuracy 0.94\n",
      "step 11600, training accuracy 0.96\n",
      "step 11700, training accuracy 0.96\n",
      "step 11800, training accuracy 0.96\n",
      "step 11900, training accuracy 0.92\n",
      "step 12000, training accuracy 0.92\n",
      "step 12100, training accuracy 0.92\n",
      "step 12200, training accuracy 0.98\n",
      "step 12300, training accuracy 0.96\n",
      "step 12400, training accuracy 0.88\n",
      "step 12500, training accuracy 0.94\n",
      "step 12600, training accuracy 0.92\n",
      "step 12700, training accuracy 0.94\n",
      "step 12800, training accuracy 0.94\n",
      "step 12900, training accuracy 0.86\n",
      "step 13000, training accuracy 0.96\n",
      "step 13100, training accuracy 0.94\n",
      "step 13200, training accuracy 0.94\n",
      "step 13300, training accuracy 0.88\n",
      "step 13400, training accuracy 0.94\n",
      "step 13500, training accuracy 0.92\n",
      "step 13600, training accuracy 0.92\n",
      "step 13700, training accuracy 0.92\n",
      "step 13800, training accuracy 0.86\n",
      "step 13900, training accuracy 0.96\n",
      "step 14000, training accuracy 0.96\n",
      "step 14100, training accuracy 0.94\n",
      "step 14200, training accuracy 0.98\n",
      "step 14300, training accuracy 0.96\n",
      "step 14400, training accuracy 0.92\n",
      "step 14500, training accuracy 0.94\n",
      "step 14600, training accuracy 0.94\n",
      "step 14700, training accuracy 0.96\n",
      "step 14800, training accuracy 0.92\n",
      "step 14900, training accuracy 0.88\n",
      "step 15000, training accuracy 0.96\n",
      "step 15100, training accuracy 0.88\n",
      "step 15200, training accuracy 0.9\n",
      "step 15300, training accuracy 0.94\n",
      "step 15400, training accuracy 1\n",
      "step 15500, training accuracy 0.92\n",
      "step 15600, training accuracy 0.92\n",
      "step 15700, training accuracy 0.94\n",
      "step 15800, training accuracy 0.92\n",
      "step 15900, training accuracy 0.88\n",
      "step 16000, training accuracy 0.98\n",
      "step 16100, training accuracy 0.96\n",
      "step 16200, training accuracy 0.92\n",
      "step 16300, training accuracy 0.96\n",
      "step 16400, training accuracy 0.9\n",
      "step 16500, training accuracy 0.98\n",
      "step 16600, training accuracy 0.92\n",
      "step 16700, training accuracy 0.9\n",
      "step 16800, training accuracy 0.96\n",
      "step 16900, training accuracy 0.94\n",
      "step 17000, training accuracy 0.96\n",
      "step 17100, training accuracy 0.88\n",
      "step 17200, training accuracy 0.94\n",
      "step 17300, training accuracy 0.96\n",
      "step 17400, training accuracy 0.88\n",
      "step 17500, training accuracy 0.9\n",
      "step 17600, training accuracy 0.96\n",
      "step 17700, training accuracy 0.92\n",
      "step 17800, training accuracy 0.98\n",
      "step 17900, training accuracy 0.94\n",
      "step 18000, training accuracy 0.98\n",
      "step 18100, training accuracy 0.9\n",
      "step 18200, training accuracy 0.9\n",
      "step 18300, training accuracy 0.96\n",
      "step 18400, training accuracy 0.94\n",
      "step 18500, training accuracy 0.98\n",
      "step 18600, training accuracy 0.9\n",
      "step 18700, training accuracy 0.84\n",
      "step 18800, training accuracy 0.94\n",
      "step 18900, training accuracy 0.96\n",
      "step 19000, training accuracy 0.92\n",
      "step 19100, training accuracy 0.94\n",
      "step 19200, training accuracy 0.88\n",
      "step 19300, training accuracy 0.9\n",
      "step 19400, training accuracy 0.88\n",
      "step 19500, training accuracy 0.96\n",
      "step 19600, training accuracy 0.98\n",
      "step 19700, training accuracy 0.98\n",
      "step 19800, training accuracy 0.88\n",
      "step 19900, training accuracy 0.94\n",
      "test accuracy 0.9383\n"
     ]
    }
   ],
   "source": [
    "import pickle, gzip, numpy, math\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "\n",
    "# we create the session\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# we initiate the computationnal graph\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "#Simple function to create a wieght variable out of normal random numbers\n",
    "def weight_variable(shape, given_name):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial, name=given_name)\n",
    "\n",
    "#Function to create a constant tensor for the biases\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "#We define this function to gian some space, also the strides and padding will always be the same\n",
    "#Strides at 1 means that the kernel will travel all around the image, pixel per pixel\n",
    "#Padding = SAME means that the output image will be 28x28 by adding a padding of 1 pixel on each side\n",
    "#Since output_size = image_size - kernel_size + 1\n",
    "#So we would have had 26x26 images, which is no good. Now we will have 28x28 convolved images\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "#We initialize the kernels & bias for the first convolution\n",
    "W_conv1 = weight_variable([3, 3, 1, 6], \"First_conv\")\n",
    "b_conv1 = bias_variable([6])\n",
    "#We reshape x in order to convolve it with W1 whose size is [3,3,1,6], because X's shape is [?, 784] right now\n",
    "x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "#And we convolve the two of them and make the result go through a rectifier as an activtion function\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "\n",
    "#We initialize the second kernels and bias\n",
    "W_conv2 = weight_variable([3, 3, 6, 6], \"Second_conv\")\n",
    "b_conv2 = bias_variable([6])\n",
    "#And we convolve the previous result with the new kernels\n",
    "h_conv2 = tf.nn.relu(conv2d(h_conv1, W_conv2) + b_conv2)\n",
    "\n",
    "#Now that the image has been convolved twice, we will softmax the results which will represent the third layer of the CNN\n",
    "W_fc1 = weight_variable([28 * 28 * 6, 10], \"Softmax\")\n",
    "b_fc1 = bias_variable([10])\n",
    "h_conv2_flat = tf.reshape(h_conv2, [-1, 28*28*6])\n",
    "\n",
    "#And here we have the result of the whole process\n",
    "y_conv = tf.nn.softmax(tf.matmul(h_conv2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "#We create this cross_entropy vector by softmaxing y_conv and applying a mean algorithm on it\n",
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))\n",
    "#Then we optimize the training by calculating the train_step that will be the best for us\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "#We calculate the correct predictions by comparing y_conv and y\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "#And calculate the accuracy by simply applying the mean algorithm\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "#Here is the training!\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #This is basically the epoch\n",
    "    for i in range(20000):\n",
    "        #Shuffling the dataset, 50 at a time to maintain some relationship between the samples\n",
    "        batch = mnist.train.next_batch(50)\n",
    "        #Every 100 iterations (fewer prints)\n",
    "        if i % 100 == 0:\n",
    "            #We calculate the current accuracy and print it\n",
    "            train_accuracy = accuracy.eval(feed_dict={\n",
    "                x: batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "            print('step %d, training accuracy %g' % (i, train_accuracy))\n",
    "        #And we train again the model\n",
    "        train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "    #The next 2 lines are here to print the final values of the kernels later on\n",
    "    variables_names = [v.name for v in tf.trainable_variables()]\n",
    "    values = sess.run(variables_names)\n",
    "    #After we trained, we calculate the accuracy of the model by testing it with new data\n",
    "    print('test accuracy %g' % accuracy.eval(feed_dict={\n",
    "        x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print of the weights of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First_conv:0\n",
      "[[[[ 0.41040269 -0.24751025 -0.02143869 -0.08657531  0.49471778 -0.15619288]]\n",
      "\n",
      "  [[ 0.21743721 -0.10778099  0.02708933  0.05726246  0.4997879  -0.03044852]]\n",
      "\n",
      "  [[ 0.20509793 -0.13276838 -0.29111812  0.05846177  0.39199898 -0.25167939]]]\n",
      "\n",
      "\n",
      " [[[ 0.34010619 -0.18600784 -0.19548735 -0.24181874  0.29769245 -0.1752955 ]]\n",
      "\n",
      "  [[ 0.19219247 -0.21399131 -0.19083185 -0.02770928  0.28351545 -0.16490547]]\n",
      "\n",
      "  [[ 0.07996404 -0.07903549 -0.08292654 -0.30114734  0.39681226 -0.15142746]]]\n",
      "\n",
      "\n",
      " [[[ 0.11254784 -0.28572974 -0.24157012 -0.29847753 -0.01149186 -0.12195846]]\n",
      "\n",
      "  [[ 0.10432011 -0.09811818 -0.15643612 -0.05929291 -0.02031766 -0.17199965]]\n",
      "\n",
      "  [[-0.06009627 -0.1670676   0.01220296 -0.08182309  0.02755539 -0.04755379]]]]\n",
      "Second_conv:0\n",
      "[[[[ 0.00037815 -0.13597956  0.19302335  0.1910414  -0.08074488  0.14495184]\n",
      "   [ 0.03262785  0.35274938  0.07395323 -0.00901592  0.15325676 -0.10162979]\n",
      "   [-0.06974695  0.29939443  0.01173009 -0.10176157 -0.00187154 -0.21027333]\n",
      "   [ 0.02178338  0.29787987  0.1185204  -0.08758993  0.14359878 -0.0877428 ]\n",
      "   [ 0.2024378  -0.23182082  0.28564939  0.1360234   0.05870641  0.12007435]\n",
      "   [ 0.06764567  0.33838981  0.01627318  0.03915003 -0.04472414 -0.04741898]]\n",
      "\n",
      "  [[-0.05617351 -0.12686168  0.00817959  0.10429692 -0.15365277  0.26451895]\n",
      "   [ 0.06752893  0.12045555 -0.0640059  -0.03316309  0.03277756  0.08057648]\n",
      "   [ 0.07408153  0.15004382 -0.09483536  0.08687513  0.22600575 -0.16462895]\n",
      "   [-0.19315746  0.18833961  0.00462952 -0.04430916  0.06396473 -0.11698101]\n",
      "   [ 0.19414744  0.00390476  0.25730357  0.09061676 -0.07515191  0.30111954]\n",
      "   [-0.10563017  0.19537148 -0.14649402  0.00123196  0.24305767 -0.12528422]]\n",
      "\n",
      "  [[ 0.11687999 -0.11900715  0.02196811  0.1509386   0.07780661  0.17909126]\n",
      "   [-0.01190179 -0.01262206 -0.11590776  0.00196646  0.17843206 -0.22975282]\n",
      "   [-0.1010447  -0.01052767 -0.19097702  0.15648212  0.33760795 -0.13095593]\n",
      "   [-0.15786439  0.2749548  -0.02254516  0.08333226  0.13979641 -0.12217343]\n",
      "   [-0.02661981  0.02821388  0.17915481  0.10076319 -0.25032187  0.19088823]\n",
      "   [ 0.1705378   0.11250859 -0.17207409  0.14794594  0.18274844 -0.11740284]]]\n",
      "\n",
      "\n",
      " [[[ 0.07400756 -0.16082504 -0.03534185  0.09984767 -0.11816595  0.12777583]\n",
      "   [-0.03572556  0.37763399  0.0384867  -0.12439966  0.07999376 -0.00446962]\n",
      "   [-0.03507366  0.23845799  0.12310722 -0.1081647   0.10773747 -0.07011096]\n",
      "   [-0.16299085  0.28232962  0.07594377 -0.05688146  0.10576212 -0.10996967]\n",
      "   [ 0.05660344 -0.03121726  0.04233833  0.16729839 -0.08236013  0.30687124]\n",
      "   [ 0.01236083  0.24039239  0.2325888  -0.04171712  0.22839335 -0.13433717]]\n",
      "\n",
      "  [[ 0.2158674   0.06564656 -0.0652279   0.21275324  0.08035367  0.18480846]\n",
      "   [-0.16009821  0.15391524  0.06070998  0.02891454  0.27107757 -0.0673556 ]\n",
      "   [-0.20243812  0.32282373 -0.03527258  0.09149221  0.12245841 -0.05387554]\n",
      "   [-0.24514994  0.17978655  0.19851072  0.19995497  0.14050244 -0.04109915]\n",
      "   [ 0.10157207 -0.14862123 -0.04045689  0.20784533 -0.26561102  0.18115434]\n",
      "   [-0.02613013  0.06189164 -0.05587591  0.01613038  0.28065887 -0.05108699]]\n",
      "\n",
      "  [[ 0.05194927 -0.17556572 -0.11661493  0.04740574  0.1193919   0.01445447]\n",
      "   [-0.08700014  0.08320104  0.06010056  0.13451651  0.13548908  0.09408815]\n",
      "   [ 0.10693603  0.20737137  0.01434914 -0.07242719  0.13050482 -0.16572559]\n",
      "   [-0.09836017  0.09676281  0.0367141   0.08481444  0.19542377  0.06599451]\n",
      "   [ 0.21231945  0.04651601  0.1091382  -0.12570213 -0.17724216  0.28677088]\n",
      "   [ 0.06450263  0.11785977 -0.00568882  0.11502004  0.27416572 -0.07416645]]]\n",
      "\n",
      "\n",
      " [[[ 0.05707912 -0.19110937 -0.27251306  0.11304776  0.01589699  0.00589203]\n",
      "   [ 0.05111856  0.11771484  0.22077781 -0.09728304  0.04388236 -0.00428352]\n",
      "   [-0.00865121  0.13948919  0.04424758 -0.04963571  0.09261363 -0.11500388]\n",
      "   [-0.13047166  0.12750235  0.23442201 -0.07530062  0.04614639 -0.17768227]\n",
      "   [ 0.36105296  0.01629725 -0.06379282 -0.08543853  0.0036762   0.16776346]\n",
      "   [-0.22344176  0.12066483  0.24054515 -0.07465959  0.23176943 -0.16714525]]\n",
      "\n",
      "  [[ 0.34124929 -0.21352157 -0.35053289  0.01162924 -0.13118812  0.1752411 ]\n",
      "   [-0.13317961  0.14605938  0.22194661 -0.0883658   0.2626532  -0.0531407 ]\n",
      "   [-0.09658998  0.09205252  0.21658732  0.15931819  0.31342667 -0.14592905]\n",
      "   [-0.18182227  0.27697316  0.19237639  0.18591788  0.08333923  0.05262751]\n",
      "   [ 0.31714687 -0.27173626 -0.20384634  0.01820151 -0.18624485  0.22491097]\n",
      "   [-0.17114903  0.02255667  0.14787827  0.13729765  0.08900695 -0.02244359]]\n",
      "\n",
      "  [[ 0.01876842 -0.25528011 -0.19552842 -0.15057141 -0.0287725   0.23960805]\n",
      "   [-0.14997439 -0.00159274  0.1535949   0.00769276  0.06026905  0.09184639]\n",
      "   [-0.02463632  0.05028041  0.03197758  0.01605732  0.08109739 -0.02911935]\n",
      "   [-0.06122398  0.12661918  0.2234482   0.11252963  0.11941572 -0.09794588]\n",
      "   [ 0.16342564 -0.0264641  -0.10481445 -0.06312557  0.02338864  0.15910938]\n",
      "   [-0.1325645  -0.06602269  0.17522666 -0.0674454   0.29186466  0.01957357]]]]\n"
     ]
    }
   ],
   "source": [
    "for k, v in zip(variables_names, values):\n",
    "    if (k==\"First_conv:0\") or (k==\"Second_conv:0\"):\n",
    "        print (k)\n",
    "        print (v)\n",
    "\n",
    "#Those are the convolution kernels, the patterns we want to scan on every image.\n",
    "#The first_conv variable below is simply 6 kernels of size 3x3. It is hard to see it of course due to the amount of numbers.\n",
    "\n",
    "#Let's say one of these \"filters\" is a vertical line : [[0,1,0][0,1,0][0,1,0]]\n",
    "#Then if passing through the image, it reveals that the number is having this pattern, \n",
    "#we can conclude it is a 1, 4 or 5 for example.\n",
    "\n",
    "#Those numbers are the patterns we want to look after in the images to have this program recognize handwritten numbers.\n",
    "#This website is a great example of illustration : http://cs.stanford.edu/people/karpathy/convnetjs/demo/cifar10.html\n",
    "\n",
    "#The second layer is the same idea but instead of applying it to the images of the numbers, \n",
    "#we apply it to the first layer of convoluted images, which allow greater accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialasing the kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "step 0, training accuracy 0.1\n",
      "step 100, training accuracy 0.26\n",
      "step 200, training accuracy 0.56\n",
      "step 300, training accuracy 0.36\n",
      "step 400, training accuracy 0.68\n",
      "step 500, training accuracy 0.6\n",
      "step 600, training accuracy 0.64\n",
      "step 700, training accuracy 0.68\n",
      "step 800, training accuracy 0.66\n",
      "step 900, training accuracy 0.72\n",
      "test accuracy 0.6697\n",
      "First_conv_set:0\n",
      "[[[[-0.08505905 -0.09973254 -0.1043578  -0.03310198 -0.08401346  0.11194234]]\n",
      "\n",
      "  [[ 0.11677647  0.06157358 -0.00574576  0.06438847 -0.03816743  0.02394777]]\n",
      "\n",
      "  [[-0.09995101 -0.17703106 -0.14432123  0.15987951 -0.06459424  0.11894002]]]\n",
      "\n",
      "\n",
      " [[[-0.1732191   0.15307797 -0.00638239 -0.11197487 -0.21371037  0.0356686 ]]\n",
      "\n",
      "  [[-0.09475678 -0.02942334 -0.0940045  -0.02113312 -0.07599565  0.09439847]]\n",
      "\n",
      "  [[-0.13381395 -0.06114966 -0.08357539 -0.05305133 -0.22972138  0.19428729]]]\n",
      "\n",
      "\n",
      " [[[-0.0151434   0.07575006 -0.03117364  0.02006509 -0.07984089  0.00948504]]\n",
      "\n",
      "  [[-0.11182041 -0.1300278  -0.01237256  0.02612781  0.04123534  0.11147305]]\n",
      "\n",
      "  [[-0.18804093 -0.13915341  0.14682907 -0.21606408 -0.07887612  0.06747941]]]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pickle, gzip, numpy, math\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "\n",
    "# we create the session\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# we initiate the computationnal graph\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "\n",
    "# we create the session\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# we initiate the computationnal graph\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "def weight_variable(shape, given_name):\n",
    "    if(given_name==\"First_conv\"):\n",
    "        initial = [[[[-1,0.5,-1,-1,-1,-1]],\n",
    "                    [[1,1,-1,-1,-1,-1]],\n",
    "                    [[0.5,0.5,-1,-1,-1,1]]],\n",
    "                    \n",
    "                   [[[-1,1,1,-1,1,-1]],\n",
    "                    [[-1,-1,-1,1,1,1]],\n",
    "                    [[1,1,1,-1,1,1]]],\n",
    "                    \n",
    "                   [[[-1,-1,0.5,-1,-1,1]],\n",
    "                    [[1,-1,1,1,-1,-1]],\n",
    "                    [[0.5,-1,0.5,-1,-1,-1]]]]\n",
    "\n",
    "    else:\n",
    "        initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    \n",
    "    return tf.Variable(initial, name=given_name)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "W_conv1 = weight_variable([3, 3, 1, 6], \"First_conv_set\")\n",
    "b_conv1 = bias_variable([6])\n",
    "x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "\n",
    "\n",
    "W_conv2 = weight_variable([3, 3, 6, 6], \"Second_conv_set\")\n",
    "b_conv2 = bias_variable([6])\n",
    "h_conv2 = tf.nn.relu(conv2d(h_conv1, W_conv2) + b_conv2)\n",
    "\n",
    "W_fc1 = weight_variable([28 * 28 * 6, 10], \"Softmax_set\")\n",
    "b_fc1 = bias_variable([10])\n",
    "h_conv2_flat = tf.reshape(h_conv2, [-1, 28*28*6])\n",
    "\n",
    "y_conv = tf.nn.softmax(tf.matmul(h_conv2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(1000):\n",
    "        batch = mnist.train.next_batch(50)\n",
    "        if i % 100 == 0:\n",
    "            train_accuracy = accuracy.eval(feed_dict={\n",
    "                x: batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "            print('step %d, training accuracy %g' % (i, train_accuracy))\n",
    "        train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "    variables_names = [v.name for v in tf.trainable_variables()]\n",
    "    values = sess.run(variables_names)\n",
    "    print('test accuracy %g' % accuracy.eval(feed_dict={\n",
    "        x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))\n",
    "    \n",
    "for k, v in zip(variables_names, values):\n",
    "    if (k==\"First_conv_set:0\"):\n",
    "        print (k)\n",
    "        print (v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We initialise the first kernel \n",
    "We did a small study to find the patterns we wanted to implement\n",
    "\n",
    "![deep_1.png](attachment:deep_1.png)\n",
    "(IF IMAGE DOES NOT DISPLAY : https://i.imgur.com/ytaklrz.jpg)\n",
    "\n",
    "It was rather easy at this point to say \"ok, let's implement it\".\n",
    "The problem came when we saw the shape of W1, since it is like a stack of 6 3x3 pictures. We tried to guess how the kernels were rearranged in this rectangular cuboid (or pav√© droit in french) also known as brick.\n",
    "\n",
    "We then came up with that :\n",
    "\n",
    "![deep_2.png](attachment:deep_2.png)\n",
    "(IF IMAGE DOES NOT DISPLAY : https://i.imgur.com/2heocic.jpg)\n",
    "\n",
    "which resulted in that code : \n",
    "        initial = [[[[-1,0.5,-1,-1,-1,-1]],\n",
    "                    [[1,1,-1,-1,-1,-1]],\n",
    "                    [[0.5,0.5,-1,-1,-1,1]]],\n",
    "                    \n",
    "                   [[[-1,1,1,-1,1,-1]],\n",
    "                    [[-1,-1,-1,1,1,1]],\n",
    "                    [[1,1,1,-1,1,1]]],\n",
    "                    \n",
    "                   [[[-1,-1,0.5,-1,-1,1]],\n",
    "                    [[1,-1,1,1,-1,-1]],\n",
    "                    [[0.5,-1,0.5,-1,-1,-1]]]]\n",
    "                    \n",
    "So here are the results\n",
    "\n",
    "On 1000 samples :\n",
    "\n",
    "\n",
    "   With the random weights |      With initialized weights<br>\n",
    "step 000, 0.14 | 0.1<br>\n",
    "step 100, 0.16 | 0.46<br>\n",
    "step 200, 0.26 | 0.6<br>\n",
    "step 300, 0.54 | 0.62<br>\n",
    "step 400, 0.64 | 0.7<br>\n",
    "step 500, 0.72 | 0.78<br>\n",
    "step 600, 0.62 | 0.92<br>\n",
    "step 700, 0.68 | 0.8<br>\n",
    "step 800, 0.76 | 0.8<br>\n",
    "step 900, 0.72 | 0.96<br>\n",
    "test accuracy 0.7958 | 0.9072<br>\n",
    "\n",
    "<br>\n",
    "But the kernel alues are modified by backpropagation, so in the end, we can see that the accuracy goes up way faster than with the random kernel but with 20000 epoch, it is not really distinguishable. Still, that's quite cool."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
